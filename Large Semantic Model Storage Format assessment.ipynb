{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b02e70-19cd-441e-a443-d09e5fdc48c4",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Moving Power BI Semantic Models in Large Semantic Model Storage Format Across Regions\n",
    "#### Background and Purpose\n",
    "Power BI semantic models (formerly known as \"datasets\") that use the \"Large Semantic Model\" storage format can not be moved across regions (as documented in the following article: https://learn.microsoft.com/en-us/fabric/admin/service-admin-premium-multi-geo?tabs=power-bi-premium). If a workspace containing a semantic model in large storage format is assigned to a capacity in a different region, the semantic model will become unusable (i.e., reports associated this semantic model will fail to load).\n",
    "\n",
    "This notebook is intended to help you identify semantic models that use the large semantic model storage format across your Fabric tenant when you are considering moving certain workspaces to capacities in different regions. If you have such semantic models, remediation suggestions provided at the bottom of the notebook will help you understand potential options for completing the move.\n",
    "\n",
    "#### Usage Instructions\n",
    "##### Prerequisites\n",
    "1. This notebook is intended to be hosted and run in a workspace hosted on a Fabric/Premium capacity in your Fabric tenant.\n",
    "1. This notebook uses the Semantic Link library which assists with the authentication to Power BI Rest APIs using the identity of the user running this notebook.\n",
    "1. This notebook uses Power BI Admin APIs and requires the user running this notebook to be a member of the Fabric Admin role.\n",
    "\n",
    "##### Running the Notebook\n",
    "1. If desired, specify the list of capacities to be evaluated. If you leave the list blank, all capacities will be evaluated.\n",
    "1. Press the \"Run all\" button to execute all cells in the notebook\n",
    "1. Review the list of Semantic Models using the Large Semantic Model Storage Format found across your tenant\n",
    "1. Review and apply relevant remediation suggestions listed at the bottom of this notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288574d2-74da-4aef-92ba-fd99bafbb1f3",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Initialize the list of relevant capacities \n",
    "capacities = []\n",
    "\n",
    "#If desired, specify capacities that you are interested in reviewing, by modifying the example below.\n",
    "#If the capacities list is left empty, this notebook will analyze all capacities across the tenant\n",
    "#capacities = [\n",
    "#    'f8d9f93e-7fbe-4f7a-aed2-ca32bef55467',\n",
    "#    '24345ed5-eeb2-4236-AF78-a66cb3f60242'\n",
    "#    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1413f90d-6b14-4327-ac0c-b2f473d6fa7b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import sempy, json, time\n",
    "import sempy.fabric as fabric\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2619e98-a261-4cdc-b513-935106cd09ac",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Convert list of capacities to lower case\n",
    "capacities = [x.lower() for x in capacities]\n",
    "\n",
    "#Get a list of workspaces\n",
    "df = fabric.list_workspaces()\n",
    "\n",
    "#Make sure that the workspaces are on a Fabric/Premium capacity\n",
    "df = df[df['Is On Dedicated Capacity']]\n",
    "\n",
    "#If a list of capacities was specified ensure that the workspace is on the capacity of interest\n",
    "if capacities != []:\n",
    "    df = df[df['Capacity Id'].isin(capacities)]\n",
    "\n",
    "#Convert a list of workspace Ids to list\n",
    "workspaces = df.Id.to_list()\n",
    "\n",
    "#Define a function to initiate a metadata scan of relevant workspaces\n",
    "def scanWorkspaces(workspaces):\n",
    "    #Add the list of workspaces to the body of the request payload and submit a Post request to the scanner API endpoint\n",
    "    body = {}\n",
    "    body['workspaces'] = workspaces\n",
    "\n",
    "    client = fabric.PowerBIRestClient()\n",
    "    response = client.post(f\"/v1.0/myorg/admin/workspaces/getInfo\", json = body)\n",
    "\n",
    "    #Get scanId\n",
    "    return response.json()['id']\n",
    "\n",
    "#Get scanId\n",
    "scanId = scanWorkspaces(workspaces)\n",
    "print('Metadata Scan Id: ' + scanId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bafcc5-8516-4d27-a4c2-25cd46aa8981",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Define a function to get scan status\n",
    "def getScanStatus(scanId):\n",
    "    client = fabric.PowerBIRestClient()\n",
    "    uri = f\"/v1.0/myorg/admin/workspaces/scanStatus/\" + scanId\n",
    "    status = client.get(uri).json()['status']\n",
    "    if status != 'Succeeded':\n",
    "        raise ValueError(\"The status is not a success\")\n",
    "    else: \n",
    "        return status\n",
    "\n",
    "#Define a function to call another function with an exponential backoff\n",
    "def callWithBackoff(function, args=None, kwargs=None, maxRetries = 2, initialDelaySeconds = 1):\n",
    "    if args is None:\n",
    "        args = []\n",
    "    if kwargs is None:\n",
    "        kwargs = {}\n",
    "    i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            return function(*args, **kwargs)\n",
    "        except:\n",
    "            if i == maxRetries:\n",
    "                raise TimeoutError(\"Maximum number of retries has been exceeded! For large Fabric tenants, consider increasing the number of retries!\")\n",
    "    delay = (initialDelaySeconds * pow(2, i))\n",
    "    time.sleep(delay)\n",
    "    i += 1\n",
    "\n",
    "#Construct the mapping of arguments\n",
    "scanIdKwargs = {}\n",
    "scanIdKwargs[\"scanId\"] = scanId\n",
    "\n",
    "#Get the Scan status while implementing the exponential backoff\n",
    "response = callWithBackoff(getScanStatus, args=None, kwargs = scanIdKwargs, maxRetries = 8, initialDelaySeconds = 5)\n",
    "print('Metadata Scan Status: ' + response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a7a07e-a106-4db9-b764-edff0b97c208",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Define a function to retrieve scan results for a completed scan\n",
    "def getScanResults(scanId):\n",
    "    client = fabric.PowerBIRestClient()\n",
    "    response = client.get(f\"/v1.0/myorg/admin/workspaces/scanResult/\" + scanId)\n",
    "    return response.json()\n",
    "\n",
    "#Get scan results\n",
    "scanResults = getScanResults(scanId)\n",
    "print('Scan results retrieved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f97dcc-3d69-4ca5-a50f-25f13aaa6d64",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### The following semantic models use Large Semantic Model Storage Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7856ea10-1b14-4e2c-8514-700cfce1c641",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Construct a Pandas data frame composed of the flattened JSON document\n",
    "df = pd.json_normalize(scanResults, record_path = ['workspaces', 'datasets'], meta=[['workspace','capacityId'],['workspace', 'id'],['workspace', 'name']]) \n",
    "\n",
    "# Filter semantic models where 'targetStorageMode' == 'PremiumFiles'\n",
    "df = df[df['targetStorageMode'] == \"PremiumFiles\"]\n",
    "\n",
    "print('Found ' + str(df.shape[0]) + ' semantic models that use the Large Semantic Model Storage Format')\n",
    "\n",
    "# Select relevant columns\n",
    "df[['workspace.capacityId', 'workspace.id', 'workspace.name', 'id', 'name', 'targetStorageMode', 'createdDate', 'configuredBy']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a979d637-58d4-4a1c-bef3-a228fcd301b9",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Remediation Suggestions\n",
    "If you determine that you have semantic models in the Large Semantic Model Storage Format that you would like to move to a different region, you have several remediation options. The following options are listed in the order of complexity -- consider using the simplest option that would be sufficient to address your requirements. These suggestions are not intended to serve as a detailed step-by-step migration guide, but rather offer high-level ideas on how to execute the migration.\n",
    "\n",
    "##### Option 1: Switch to small semantic model storage format\n",
    "Check the size of the semantic model. If the semantic model is less than 10GB in size, you should be able to switch the semantic model to the \"Small Semantic Model Storage Format\" in preparation for the migration to another region.  Once the workspace containing your semantic model has been reassigned to a capacity in another region, you should be able to switch the semantic model back to the Large Semantic Model storage format in order to take advantage of performance benefits offered by this format.\n",
    "\n",
    "```\n",
    "Note: semantic models larger than 10GB cannot be switched to the small semantic model storage format.\n",
    "```\n",
    "\n",
    "##### Option 2: Redeploy semantic model as a new item\n",
    "If your semantic model is too large to allow you to use Option 1, you may deploy your semantic model to the destination workspace in another region (as if it were a new model). Once the semantic model has been re-deployed you may need to refresh the semantic model to populate it with data, configure refresh schedules, configure permissions to match the configuration settings of your original semantic model. Similarly any reports or derived semantic models that depend on the original semantic model will need to be re-bound to the newly-deployed semantic model. Once your new semantic model has been deployed and properly configured, you may delete the original semantic model from the source workspace.\n",
    "\n",
    "```\n",
    "Note: for heavily-used semantic models with complex permissions and extensive downstream dependencies, re-deploying the semantic model will require additional effort.\n",
    "```\n",
    "\n",
    "##### Option 3: Shrink semantic model and switch to small semantic model storage format\n",
    "If re-deploying your semantic model as outlined in Option 2 is undesirable, you may consider shrinking the size of the semantic model by performing a refresh operation that clears values from your semantic model. More specifically, you will execute the \"clearValues\" refresh. This refresh type can be performed over the XMLA endpoint (https://learn.microsoft.com/en-us/analysis-services/tmsl/refresh-command-tmsl?view=asallproducts-allversions#:~:text=all%20its%20dependents.-,clearValues,-Database%2C%0ATable) or using the advanced refresh REST API (https://learn.microsoft.com/en-us/rest/api/power-bi/datasets/refresh-dataset#datasetrefreshtype). \n",
    "\n",
    "Once the clearValues refresh has been performed, the semantic model can be switched to the small semantic model storage format and the workspace containing the model can be moved to a capacity in the desired region. After the move, the semantic model can be switched back to the \"large semantic model storage format\" and refreshed to populate it with data.\n",
    "\n",
    "```\n",
    "Caution: performing the clearValues refresh will result in the deletion of all data from the semantic model -- therefore, please be sure that you have access to source data and can \"rehydrate\" the semantic model by refreshing it after the workspace containing the model has been moved to the target region.\n",
    "```\n",
    "\n",
    "##### Option 4: Backup and restore your semantic model\n",
    "If Option 3 is not viable (for instance, if the historical source data that has been imported into the semantic model as part of an incremental refresh process is no longer available), you may consider the following methodology to complete the refresh process.\n",
    "1. [Backup the semantic mode to ADLS Gen2l](https://learn.microsoft.com/en-us/power-bi/enterprise/service-premium-backup-restore-dataset)\n",
    "1. Restore the semantic model from backup to a workspace hosted on a capacity in the desired region.\n",
    "\n",
    "```\n",
    "Note: Once the semantic model has been restored, you will need to complete additional configuration steps, such as configure refresh schedules, configure permissions to match the configuration settings of your original semantic model. Similarly any reports or derived semantic models that depend on the original semantic model will need to be re-bound to the newly-deployed semantic model.\n",
    "```\n",
    "##### Option 5: Backup, migrate and restore your semantic model\n",
    "Finally, you may consider a hybrid strategy that combines Option 3 and Option 4. While this approach involves the greatest number of steps, it allows you to preserve historical data as well as the configuration settings of the existing semantic model that needs to be migrated to a workspace on a capacity in another region.\n",
    "1. [Backup the semantic mode to ADLS Gen2l](https://learn.microsoft.com/en-us/power-bi/enterprise/service-premium-backup-restore-dataset)\n",
    "1. Shrink the semantic model by performing the clearValues refresh (as described in Option 3)\n",
    "1. Switch the semantic model to the small semantic model storage format\n",
    "1. Move the semantic model to the desired region (by assigning the workspace hosting the model to a suitable capacity in the target region)\n",
    "1. Switch the semantic model back to the large semantic model storage format\n",
    "1. Restore the semantic model from backup (by overwriting the existing model that has just been migrated)\n",
    "\n",
    "#### Conclusion\n",
    "After reviewing the list of semantic models that use the Large Semantic Model Storage Format, select an optimal remediation option for each of the affected semantic models. Consider using the simplest option that would be sufficient to address your requirements. Finally, complete the migration of your workspaces to a capacity in a different region."
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {}
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default"
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
